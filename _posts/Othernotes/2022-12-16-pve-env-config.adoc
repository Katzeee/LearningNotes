= Pve Env Config
:revdate: 2022.12.16
:page-category: Othernotes
:page-tags: [pve]
:experimental:

== Bios Setting(important for hardware pass-through)

* Enable IOMMU: for IO divide
* SVM mode: virtualize
* SCM disable(UEFI boot): proxmox boot mode
* VT-D(intel), AMD-V(AMD) # maybe not necessary

== Install PVE

=== Install

Download pve-iso from https://proxmox.com/en/downloads/category/iso-images-pve[pve-download^].

Use `rufus` to create a bootable USB drive(GPT then DD).

Boot from your usb device and just press continue, maybe to set your dns server address as `8.8.8.8` instead of your gateway address will be more robust.

Then you can login pve system from another pc's browser at `https://<your-ip-addr>:8006`

WARNING: **https** not [line-through]#http#

=== Extra Config

*Try to use pve-tools*

```bash
$ apt update && apt -y install git && git clone https://github.com/ivanhao/pvetools.git
```

Change mirror sources

./etc/apt/sources.list 
```bash
deb https://mirrors.aliyun.com/debian buster main contrib non-free
deb https://mirrors.aliyun.com/debian buster-updates main contrib non-free
deb https://mirrors.aliyun.com/debian-security buster/updates main contrib non-free # proxmox source
deb https://mirrors.ustc.edu.cn/proxmox/debian/pve buster pve-no-subscription
```

Comment enterprise source

./etc/apt/sources.list.d/pve-enterprise.list
```bash
# deb https://enterprise.proxmox.com/debian/pve buster pve-enterprise
```

=== IOMMU and hardware pass-through

> https://zhuanlan.zhihu.com/p/438793914

./etc/default/grub
```diff
- GRUB_CMDLINE_LINUX_DEFAULT="quiet"

# For AMD users
+ GRUB_CMDLINE_LINUX_DEFAULT="quiet amd_iommu=on pcie_acs_override=downstream,multifunction video=vesafb:off video=efifb:off"
```
Some of them may not necessary, but I added `pcie_acs_override=downstream,multifunction`

NOTE: `efifb:off` disable efi-booting display devices, `vesafb:off` disable vesa-booting display devices

then `update-grub`

./etc/modules
```diff
+ vfio
+ vfio_iommu_type1
+ vfio_pci
+ vfio_virqfd
```

then reboot

=== Enable ipv6

Append these to `/etc/sysctl.conf`, reboot.

```config
net.ipv6.conf.all.accept_ra=2
net.ipv6.conf.default.accept_ra=2
net.ipv6.conf.vmbr0.accept_ra=2
net.ipv6.conf.all.autoconf=1
net.ipv6.conf.default.autoconf=1
net.ipv6.conf.vmbr0.autoconf=1
```

=== To change ip-address and examples

./etc/network/interfaces
```config
auto lo
iface lo inet loopback

iface enp34s0 inet manual

auto vmbr0
iface vmbr0 inet static
    address 192.168.2.200/24
    gateway 192.168.2.2
    bridge-ports enp34s0
    bridge-stp off
    bridge-fd 0
```

./etc/hosts
```config
127.0.0.1 localhost.localdomain localhost
192.168.2.200 xac.pve xac

# IPv6

::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
ff02::3 ip6-allhosts
```

NOTE: `/etc/issue` for welcome page, `/etc/resolv.conf` for dns server

=== DDNS

https://github.com/jeessy2/ddns-go[ddns-go^]

```bash
$ wget https://github.com/jeessy2/ddns-go/releases/download/v4.5.3/ddns-go_4.5.3_linux_x86_64.tar.gz
$ mkdir ddns-go && cd ddns-go
$ tar -zxvf ../ddns-**
$ ./ddns-go -s install
# ./ddns-go -s uninstall
```

port: 9876

// TODO: update images
create API, set up API and domain

=== ssh

./etc/ssh/sshd_config
```config
PermitRootLogin yes
PasswordAuthentication yes
```

If Use `WindTerm` as terminal

Generate ssh key in both host and client, then copy `<client>/.ssh/id_rsa.pub` to host as `<host>/.ssh/authorized_keys`, then client can ssh to host without password

In WindTerm, also set the sessions' authentication identity file as `<client>/.ssh/id_rsa` such that windterm to login host without password

== Install Openwrt

=== Download iso file

> https://github.com/coolsnowwolf/lede/releases

=== Create a virtual machine

q35, no media, 2G ram, **delete disk**

Run command `find / -name openwrt*` to get the path of our img file, then import a new disk to openwrt machine by excuting `qm importdisk <vm-id> <img-path> local-lvm`.

Add the new disk in hardware tab, then select the boot device in device tab, start openwrt.

=== Pre-config

*1. Update source*

`System->software package->configuration`, use origin source instead of local source

```text
src/gz openwrt_koolshare_mod_core http://downloads.openwrt.org/snapshots/targets/x86/64/packages
src/gz openwrt_koolshare_mod_base http://downloads.openwrt.org/snapshots/packages/x86_64/base
src/gz openwrt_koolshare_mod_luci http://downloads.openwrt.org/snapshots/packages/x86_64/luci
src/gz openwrt_koolshare_mod_packages http://downloads.openwrt.org/snapshots/packages/x86_64/packages
src/gz openwrt_koolshare_mod_routing http://downloads.openwrt.org/snapshots/packages/x86_64/routing
src/gz openwrt_koolshare_mod_telephony http://downloads.openwrt.org/snapshots/packages/x86_64/telephony
```

*2. Then run*

```bash
$ opkg update
$ opkg install qemu-ga
$ reboot
```
=== Config

* One-armed router(router on a stick)
+
--
Reserve only one lan interface, set its gateway as main router, then set every single devices manually route to openwrt. 

WARNING: You can use either main router DHCP or openwrt DHCP. Do not use both of them!

Then, for the devices you want it use openwrt as gateway, do:

```bash
$ sudo route add default gw <openwrt-ip>
$ sudo route del default
```
--

=== Setup virtual LAN via zerotier

> https://opclash.com/article/198.html +
> https://www.right.com.cn/forum/thread-476177-1-1.html

*1. Create a net on zerotier*

Just login https://my.zerotier.com[zerotier^], click `Create A Network` button. Then you will find a Network ID.

*2. Add openwrt into LAN*

image::/assets/images/openwrt-join-zerotier.png[]

Type in the network id you get last step then click `save&apply`. Allow NAT.

*3. Setup router on zerotier*

You will first find the openwrt IP at the members section, check the `Auth` box, then you will get the IP.

Add a new route under menu:Advanced[Managed Routes] section,  `Destination` should be the openwrt LAN IP in home, `Via` should be the IP got from zerotier.
  
*4. Setup network interface in openwrt*

* Create a new interface
+
image::/assets/images/openwrt-create-zerotier-interface.png[]

* Setup firewall
+
--
image::/assets/images/openwrt-zerotier-firewall1.png[]

image::/assets/images/openwrt-zerotier-firewall2.png[]
--

* Firewall custom rules
+
--
Under menu:Network[Firewall > Custom rule], add following commands, remember to substitute `ztqu3pfdod` to your interface name.

```text
iptables -I FORWARD -i ztqu3pfdod -j ACCEPT
iptables -I FORWARD -o ztqu3pfdod -j ACCEPT
iptables -t nat -I POSTROUTING -o ztqu3pfdod -j MASQUERADE
```
--

== Install Arch [[arch-install-and-config.md]]

=== Download iso file

Download iso file from 163 mirror into `local` storage.

=== Create new virtual machine

Set every options as defualt(UEFI), except those about quantities(mem, disk, cpu cores) and select to use qemu agent.

Choose the iso file as cd/rom, then boot the machine.

=== Start installation

Change source mirror, then directly start install via one command:

```bash
$ reflector --country 'China' --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist
$ https://mirrors.ustc.edu.cn/archlinux
$ archinstall
```

Set all language related options to English(or there may some font problems). You can change it in `/etc/locale.gen` later.

* Profile: minimal
* Additional package: neovim net-tools qemu-guest-agent git openssh man-db
* Network: copy from iso
* Additional repo: mutilib

=== Rest configure

Static IP:

./etc/systemd/network/**
```bash
Address: 192.168.x.x/24
Gateway: 192.168.x.x
DNS: 
```

TIP: If git clone fail

Fail with `kex_exchange_identification: Connection closed by remote host`

.~/.ssh/config
```
Host github.com
    HostName ssh.github.com
    User git
    Port 443
```

== Install windows and config GPU pass-through

=== Install windows

* System: q35, UEFI
* Disk: SCSI
* Network: virtIO

Change boot sequential, then install windows as usual, *need install https://pve.proxmox.com/wiki/Windows_VirtIO_Drivers[virtio driver^] from iso file.*

`qemu-ga` is also installed from the cd. 

=== Change resolution of screen

Change `Hardware->Display` to `SPICE`, then install qxl driver in windows(in the cd). However, this may cause the cursor position of VM not matching with the real position, add `tablet: yes` in host `/etc/pve/qemu-server/<vm-id>.conf` can solve.

=== Setup remote desktop(WIN 10)

* static ip

* RDP
+
--
Right click menu:My computer[属性 > 远程桌面]

menu:win+r[secpol.msc>本地策略>安全选项]，在右侧选中帐户: 使用空白密码的本地帐户只允许进行控制台登录

menu:网络设置[防火墙 > 高级设置 > 入站设置（最下）> TCP-WSS-IN启用]即可
--

=== GPU pass-through

. Add PCIE device: select all options except `Primary GPU`.

. Install GPU driver, check whether GPU is working.

. Change Display to `none`, add select `Primary GPU` option.

=== Hide vm from guest

Edit `/etc/pve/qemu-server/<vm-id>.conf` in pve host.

./etc/pve/qemu-server/<vm-id>.conf
```config
args: -cpu 'host,-hypervisor,+kvm_pv_unhalt,+kvm_pv_eoi,hv_spinlocks=0x1fff,hv_vapic,hv_time,hv_reset,hv_vpindex,hv_runtime,hv_relaxed,kvm=off,hv_vendor_id=null'
```

WARNING: I don't know which options are unnecessary, but it works.

== Install TrueNAS Scale(Recommended)

> https://www.truenasscale.com/

=== Create VM

Let everything default except 16G disk and 8192 mem, choose iso then start VM

=== sata controller pass-through

msi B450 gaming motherboard: choose `400 Series Chipset SATA Controller` *(without All Functions)*

=== Change Web port(For accessing from Browser)

menu:System Settings[General > GUI]

change http port from 80 to 8000 because 80 port is defaultly banned by service provider

=== SSL certificate from certbot

Reference:

> https://github.com/acmesh-official/acme.sh/wiki +
> https://u.sb/acme-sh-ssl/ + 
> https://zhuanlan.zhihu.com/p/347064501 +
> https://www.youtube.com/watch?v=BYkBJ11gDIM

*0. Change user to root*

```bash
$ sudo su
```

*1. Install acme.sh*

```bash
# If you can curl `raw.githubusercontent.com`
$ curl https://get.acme.sh | sh -s email=username@example.com 
# If you cannot
$ git clone https://gitee.com/neilpang/acme.sh.git
$ cd acme.sh
$ ./acme.sh --install -m my@example.com
```

```bash
$ source `~/.bashrc` # or reopen the shell
```

*2. Choose default CA*

```bash
$ acme.sh --set-default-ca --server letsencrypt
```

*3. link:../acme.sh-issue-ssl-cert[Issue SSL certificates^]*

Get the `Id` and `Token` from `DNSPod`

```bash
$ export DP_Id="1234"
$ export DP_Key="sADDsdasdgdsf" # API token for DP
$ acme.sh --issue --dns dns_dp -d www.example.com --keylength ec-256
```

*4. Install certificate for TrueNAS*

Click your avatar at the top right of the website, choose API key, create a new key.

```bash
$ git clone https://github.com/danb35/deploy-freenas
$ cd deploy-freenas
$ cp deploy_config.example deploy_config
$ vim deploy_config
```

Edit it 

```toml
[deploy]
api_key = 1-something
```

```bash
$ acme.sh --install-cert -d www.example.com --reloadcmd "~/deploy-freenas/deploy_freenas.py"
```

NOTE: You may also need to edit `deploy_freenas.py` to change the cert location or the truenas http service port

Then the certificates are now available in the certificate tab.

=== Add Catalog(need VPN)

menu:Apps[Manage Catalogs > Add Catalog]

Name: truecharts

Repo: https://github.com/truecharts/catalog

Trains: stable dependency

To avoid TLS fail, use `git config --global http.sslVerify false`

=== Apps

NOTE: `Host network` option is important, which ensures that the docker is running in host network.

Search `ddns-go` and `webdav` in Apps.

image::/assets/images/truenas-apps.png[]

* ddns-go
+
--
image::/assets/images/2024-04-03-truenas-ddns-go-1.png[]

image::/assets/images/2024-04-03-truenas-ddns-go-2.png[]
--

* webdav
+
--
To enable ipv6, you should check this option.

image::/assets/images/truenas-webdav.png[]

Then you can access the webdav at `http://truenas.xx.xx:30034/webdav` where `webdav` is the share name you set. 
--

=== Import to pve host

* TrueNAS:
+
--
Add dataset to NFS share, allow network `192.168.2.0/24` or host ip access. 

WARNING: Remember to set acl to 777 or you will get a permission denied error.
--

* PVE:
+
--
menu:Datacenter[Storage > New > NFS]

ID: name, Server: truenas ip, Export: path to dataset on truenas(just select)
--

== [line-through]#Install TrueNAS Core#(Not Recommended)

=== Install TrueNAS

32G disk SATA
8192 Mem

install then reboot

=== Disk pass-through

Use pvetools to pass through disks (qm set), only choose the whole sata, not sata1, sata2 or etc.

Or use SATA controller PCI pass through(may not work)

=== Config 

- Network

  Network->interface
  
  De-select DHCP, select autoconfig IPV6
  
  type in the IPV4 address
  
  TEST then confirm

- Users

  Account->Users->Add

- General

  System->General->Time zone


=== Create Pool and dataset

Storage->Pool->Create new pool->type in a name and choose which disks to compose to a what kind of pool->press create

Click the threes dots at right of the pool->add dataset

=== SMB share

Sharing->SMB

Choose the folder then submit

=== guest-agent

`cd /usr/local/etc/pkg/repos/`, change `local.conf` `enabled=yes` to `no`, change `FreeBSD.conf` `enabled=no`to `yes`.

then run command:

```bash
$ pkg install qemu-guest-agent
# Modify your `/etc/rc.conf` by adding these settings

qemu_guest_agent_enable="YES"
qemu_guest_agent_flags="-d -v -l /var/log/qemu-ga.log"

and run
# service qemu-guest-agent start
```

== LXC container

=== Install LXC container

Create CT, **deselect** `unprivilieged container`, about 20G(or 64G for not mount NAS folder) disk, 2048 mem and 2048 swap, static ip. DNS domain is the smae as gateway, DNS servers set as blank.

network ipv6 SLAAC

=== Setup intel gpu share(optional)

In pve: `vi /etc/pve/lxc/<CT_ID>.conf`

Add following(Get args by `ls -l /dev/dri`):

Mandatory!!!

```config
lxc.apparmor.profile: unconfined
lxc.cgroup.devices.allow: a
lxc.cap.drop:
```

Optional
```config
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.cgroup2.devices.allow: c 29:0 rwm
lxc.mount.entry: /dev/dri dev/dri none bind,optional,create=dir
lxc.mount.entry: /dev/fb0 dev/fb0 none bind,optional,create=file
```

Then start CT, you will see gpu by running `ls /dev/dri`.

=== Change apt source

ubuntu20.04, `vi /etc/apt/source.list`

./etc/apt/source.list
```config
deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe
```

=== localization

`sudo dpkg-reconfigure locales`

kbd:[Space] to check, kbd:[Tab] then kbd:[Enter] to <Ok>

=== Mount NAS

Or just use sftp which need to add a new user to connect to this LXC via ssh.

```bash
$ apt install cifs-utils nfs-common
$ mkdir /mnt/<folder-name>
$ vi ~/.smbcredentials # password
$ chmod .smbcredentials 600
```

type in things like 

```bash
username=<username>
password=<password>
```

Then `vi /etc/fstab`

./etc/fstab
```bash
//$smb_server/$<share> /mnt/<folder-name> cifs credentials=~/.smbcredentials,iocharset=utf8 0 0
$nfs_server:$<full-path-to-folder>(/mnt/master/pve/database) /mnt/database nfs defaults 0 0
```

Substitute `$<share>` with the smb folder name, not the path to the dataset.

Then `sudo mount -a`, you will find your smb folder

=== Install docker

*1. Docker*

```bash
$ apt install curl -y
$ curl -sSL https://get.daocloud.io/docker | sh
```

Or use the script in my dot-files.

*2. Portainer*

```bash
$ docker volume create portainer_data
$ docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce
```

Then go to <docker-CT-IP>:9000 to set up portainer.

=== Install docker containers

- Docker compose
+
menu:local[Stack > Add stack]

- Docker cmd line
+
menu:local[Container >Add container]

=== Resize the disk of LXC

```bash
$ pct df <vmid>
$ pct resize <vmid> rootfs 40G
```

NOTE: You can only expand it, not shrink.

== Install homeassitant

=== Install

One script in pve shell can help you install it

```bash
$ bash -c "$(wget -qLO - https://github.com/tteck/Proxmox/raw/main/vm/haos-vm-v4.sh)"
```

=== Set up homeassitant

* Init
+
--
You can access the manage page at `<ha-ip>:8123`

Set your username or something, enable `Advanced mode` by click your avatar at the bottom-left of your screen.
--

* Install two add-ons in menu:settings[add-ons > add-on store], which are `ssh` and `samba`
+
If there is no add-ons, add repo `https://github.com/hassio-addons/repository`.

* Install `HACS`(add-on store)

** via samba(tbc)
+
Config samba and start samba, open `\\<ha-ip>:8123` in your explore

** via ssh
+
--
Start ssh

`https://github.com/hacs-china`

```bash
$ wget -q -O - https://install.hacs.xyz | bash -
$ wget -O - https://hacs.vip/get | bash - # china
```

Restart HA, then add `HACS` integration in menu:settings[devices and services], authorize on github follow the instruction.
--

* Integrate MI devices
+ 
--
Click menu:HACS[integrations > Explore & Download repos], choose `Xiaomi MIoT`, restart HA

Then add `Xiaomi MIoT` integration, now you can see all your devices, rename the devices at web 
--

* Integrate to HomeKit
+
Add `HomeKit` integration, scan the QR code at notification panel to finish setting

=== Set up Photoprism

WARNING: If use nfs to mount database, you must change the `Maproot user` in nfs server, or the container will not get the root privilage causing database initialize failed.

Just follow one of the following step.

> https://docs.photoprism.app/getting-started/docker-compose/ +
> https://docs.photoprism.app/getting-started/portainer/

NOTE: Maybe you should mount `/photoprism/storage` to `/mnt/...`, seems it's very large. 